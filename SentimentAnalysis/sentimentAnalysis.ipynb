{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar clasificador ya hecho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import transformers\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "`return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n"
     ]
    }
   ],
   "source": [
    "classifier = transformers.pipeline(\"sentiment-analysis\", return_all_scores=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'NEGATIVE', 'score': 0.00012563355267047882},\n",
       "  {'label': 'POSITIVE', 'score': 0.9998743534088135}]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"This restaurant is awesome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar tweets con palabras claves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets para 'happy':\n",
      " If it is any consolation I got my BMI tested hahaha it says I am obesed  well so much for being unhappy for about 10 minutes.\n",
      "A little happy for the wine jeje ok it`sm my free time so who cares, jaja i love this day\n",
      " Car not happy, big big dent in boot! Hoping theyre not going to write it off, crossing fingers and waiting\n",
      "\n",
      "Tweets para 'sad':\n",
      " Sooo SAD I will miss you here in San Diego!!!\n",
      "\n",
      "Tweets para 'ever':\n",
      " as much as i love to be hopeful, i reckon the chances are minimal =P i`m never gonna get my cake and stuff\n",
      "is back home now      gonna miss every one\n",
      "\n",
      "Tweets para 'love':\n",
      " as much as i love to be hopeful, i reckon the chances are minimal =P i`m never gonna get my cake and stuff\n",
      "I really really like the song Love Story by Taylor Swift\n",
      "A little happy for the wine jeje ok it`sm my free time so who cares, jaja i love this day\n",
      "\n",
      "Tweets para 'can':\n",
      "Playing Ghost Online is really interesting. The new updates are Kirin pet and Metamorph for third job.  Can`t wait to have a dragon pet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Ruta del archivo CSV\n",
    "csv_file_path = 'dataset/Tweets.csv'\n",
    "\n",
    "# Palabras clave para buscar tweets\n",
    "keywords = ['happy', 'sad', 'ever', 'love', 'can']\n",
    "\n",
    "# Número máximo de tweets que deseas recuperar por palabra clave\n",
    "max_tweets_per_keyword = 10\n",
    "\n",
    "# Listas para almacenar los tweets por cada palabra clave\n",
    "tweets_por_palabra_clave = {keyword: [] for keyword in keywords}\n",
    "\n",
    "# Leer tweets desde el archivo CSV\n",
    "with open(csv_file_path, 'r', encoding='utf-8') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    for row in csv_reader:\n",
    "        text = row['text']\n",
    "        sentiment = row['sentiment']\n",
    "        for keyword in keywords:\n",
    "            if keyword in text.lower():\n",
    "                tweets_por_palabra_clave[keyword].append(text)\n",
    "                max_tweets_per_keyword -= 1\n",
    "                if max_tweets_per_keyword == 0:\n",
    "                    break\n",
    "        if max_tweets_per_keyword == 0:\n",
    "            break\n",
    "\n",
    "# Imprimir los tweets almacenados en las listas\n",
    "for keyword, tweets in tweets_por_palabra_clave.items():\n",
    "    print(f\"Tweets para '{keyword}':\")\n",
    "    for tweet in tweets:\n",
    "        print(tweet)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar tweets dudosos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet con probabilidades similares:\n",
      "Texto: MAYDAY?!\n",
      "Sentimiento: neutral\n",
      "Probabilidad de ser positivo: 0.455401211977005\n",
      "Probabilidad de ser negativo: 0.5445987582206726\n",
      "\n",
      "Tweet con probabilidades similares:\n",
      "Texto: Screw the reviews, I thought Wolverine was awesome. But not enough Dominic Monaghan for my liking.\n",
      "Sentimiento: positive\n",
      "Probabilidad de ser positivo: 0.5355139970779419\n",
      "Probabilidad de ser negativo: 0.4644860029220581\n",
      "\n",
      "Tweet con probabilidades similares:\n",
      "Texto:  Thx\n",
      "Sentimiento: neutral\n",
      "Probabilidad de ser positivo: 0.5395320653915405\n",
      "Probabilidad de ser negativo: 0.4604679346084595\n",
      "\n",
      "Tweet con probabilidades similares:\n",
      "Texto: _Live That`s what I want. More the better. Bound to be a few bad eggs though, but they will soon learn.\n",
      "Sentimiento: neutral\n",
      "Probabilidad de ser positivo: 0.5029829740524292\n",
      "Probabilidad de ser negativo: 0.4970170259475708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "# Leer tweets desde el archivo CSV y realizar análisis de sentimiento\n",
    "with open(csv_file_path, 'r', encoding='utf-8') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    for row in csv_reader:\n",
    "        if i>3:\n",
    "            break\n",
    "        text = row['text']\n",
    "        sentiment = row['sentiment']\n",
    "        # Realizar análisis de sentimiento\n",
    "        result = classifier(text)\n",
    "        # Obtener la probabilidad de ser positivo y negativo\n",
    "        positive_prob = result[0][0]['score'] if result[0][0]['label'] == 'POSITIVE' else result[0][1]['score']\n",
    "        negative_prob = result[0][0]['score'] if result[0][0]['label'] == 'NEGATIVE' else result[0][1]['score']\n",
    "\n",
    "        # Verificar si las probabilidades de ser positivo y negativo son similares\n",
    "        if abs(positive_prob - negative_prob) < 0.1:\n",
    "            i+=1\n",
    "            print(\"Tweet con probabilidades similares:\")\n",
    "            print(f\"Texto: {text}\")\n",
    "            print(f\"Sentimiento: {sentiment}\")\n",
    "            print(f\"Probabilidad de ser positivo: {positive_prob}\")\n",
    "            print(f\"Probabilidad de ser negativo: {negative_prob}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizaciones ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'NEGATIVE', 'score': 0.9976692795753479},\n",
       "  {'label': 'POSITIVE', 'score': 0.0023306654766201973}]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"If it is any consolation I got my BMI tested hahaha it says I am obesed  well so much for being unhappy for about 10 minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'NEGATIVE', 'score': 0.00022044003708288074},\n",
       "  {'label': 'POSITIVE', 'score': 0.9997795224189758}]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"A little happy for the wine jeje ok it`sm my free time so who cares, jaja i love this day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'NEGATIVE', 'score': 0.014478222467005253},\n",
       "  {'label': 'POSITIVE', 'score': 0.9855217933654785}]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Sooo SAD I will miss you here in San Diego!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'NEGATIVE', 'score': 0.9979243278503418},\n",
       "  {'label': 'POSITIVE', 'score': 0.002075662836432457}]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"as much as i love to be hopeful, i reckon the chances are minimal =P i`m never gonna get my cake and stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'NEGATIVE', 'score': 0.00032968970481306314},\n",
       "  {'label': 'POSITIVE', 'score': 0.9996702671051025}]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I really really like the song Love Story by Taylor Swift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'NEGATIVE', 'score': 0.999301552772522},\n",
       "  {'label': 'POSITIVE', 'score': 0.0006984112551435828}]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Can`t access your site!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'NEGATIVE', 'score': 0.4644860029220581},\n",
       "  {'label': 'POSITIVE', 'score': 0.5355139970779419}]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Screw the reviews, I thought Wolverine was awesome. But not enough Dominic Monaghan for my liking.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo Positivo\n",
    "\n",
    "A little happy for the wine jeje ok it`sm my free time so who cares, jaja i love this day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"A little happy for the wine jeje ok it`sm my free time so who cares, jaja i love this day\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=['NEGATIVE', 'POSITIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/lime/lime_text.py:429\u001b[0m, in \u001b[0;36mLimeTextExplainer.explain_instance\u001b[0;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    425\u001b[0m     ret_exp\u001b[38;5;241m.\u001b[39mtop_labels\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[1;32m    427\u001b[0m     (ret_exp\u001b[38;5;241m.\u001b[39mintercept[label],\n\u001b[1;32m    428\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mlocal_exp[label],\n\u001b[0;32m--> 429\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mscore, ret_exp\u001b[38;5;241m.\u001b[39mlocal_pred) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance_with_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_regressor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_regressor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_selection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret_exp\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/lime/lime_base.py:182\u001b[0m, in \u001b[0;36mLimeBase.explain_instance_with_data\u001b[0;34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Takes perturbed data, labels and distances, returns explanation.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    local_pred is the prediction of the explanation model on the original instance\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    181\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_fn(distances)\n\u001b[0;32m--> 182\u001b[0m labels_column \u001b[38;5;241m=\u001b[39m \u001b[43mneighborhood_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    183\u001b[0m used_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_selection(neighborhood_data,\n\u001b[1;32m    184\u001b[0m                                        labels_column,\n\u001b[1;32m    185\u001b[0m                                        weights,\n\u001b[1;32m    186\u001b[0m                                        num_features,\n\u001b[1;32m    187\u001b[0m                                        feature_selection)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_regressor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "exp = explainer.explain_instance(sentence, classifier.predict, num_samples=10, labels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/lime/lime_text.py:429\u001b[0m, in \u001b[0;36mLimeTextExplainer.explain_instance\u001b[0;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    425\u001b[0m     ret_exp\u001b[38;5;241m.\u001b[39mtop_labels\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[1;32m    427\u001b[0m     (ret_exp\u001b[38;5;241m.\u001b[39mintercept[label],\n\u001b[1;32m    428\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mlocal_exp[label],\n\u001b[0;32m--> 429\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mscore, ret_exp\u001b[38;5;241m.\u001b[39mlocal_pred) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance_with_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_regressor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_regressor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_selection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret_exp\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/lime/lime_base.py:182\u001b[0m, in \u001b[0;36mLimeBase.explain_instance_with_data\u001b[0;34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Takes perturbed data, labels and distances, returns explanation.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    local_pred is the prediction of the explanation model on the original instance\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    181\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_fn(distances)\n\u001b[0;32m--> 182\u001b[0m labels_column \u001b[38;5;241m=\u001b[39m \u001b[43mneighborhood_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    183\u001b[0m used_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_selection(neighborhood_data,\n\u001b[1;32m    184\u001b[0m                                        labels_column,\n\u001b[1;32m    185\u001b[0m                                        weights,\n\u001b[1;32m    186\u001b[0m                                        num_features,\n\u001b[1;32m    187\u001b[0m                                        feature_selection)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_regressor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "exp = explainer.explain_instance(sentence, classifier.predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
